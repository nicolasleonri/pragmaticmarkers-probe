mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
df %>% group_by(source, aggregation, )
df %>% group_by(source, aggregation, ) %>% mean(accuracy)
summary(df)
df$accuracy <- as.numeric(df$accuracy)
df %>% group_by(source, aggregation, ) %>% mean(accuracy)
summary(df)
df %>% group_by(source, aggregation, ) %>% mean(accuracy)
df %>% group_by(source, aggregation ) %>% mean(accuracy)
summary(df)
mean(df$accuracy)
df %>% group_by(source, aggregation ) %>% mean(accuracy)
df %>% group_by(source, aggregation ) %>% mean()
df %>% group_by(source, aggregation ) %>% mean(accuracy)
df %>%  group_by(source, aggregation) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = TRUE))
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = TRUE))
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = TRUE)) %>% sort(mean_accuracy)
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = TRUE)) %>% sort(mean_accuracy)
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = TRUE)) %>% sort()
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% sort()
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(mean_accuracy)
df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
%>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_aggregation_layer <- df %>%  group_by(source, aggregation, layer)
df_aggregation_layer <- df %>%  group_by(source, aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE))%>% arrange(-mean_accuracy)
View(df_aggregation_layer)
xtable(df_aggregation_layer)
install.packages("xtable")
library(xtable)
xtable(df_aggregation_layer)
df_aggregation_layer <- df %>%  group_by(aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_aggregation_layer)
df2 <- read.csv2("results/frazer_results.csv")
df2
merge(df,df2,by="experiment")
length(merge(df,df2,by="experiment"))
length(rbind(df,df2))
full_join(df, df2, by = "experiment")
############################Layerwise results##################################
# Discourse connective
df <- read.csv2("results/discourse_connective_results.csv")
df2 <- read.csv2("results/frazer_results.csv")
length(merge(df,df2,by="experiment"))
merge(df,df2,by="experiment")
rbind(df, df2)
length(rbind(df, df2))
test <- rbind(df, df2
test <- rbind(df, df2)
test <- rbind(df, df2)
############################Layerwise results##################################
# Discourse connective
df <- read.csv2("results/discourse_connective_results.csv")
df2 <- read.csv2("results/frazer_results.csv")
df <- rbind(df, df2)
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
summary(df)
df$accuracy <- as.numeric(df$accuracy)
df_aggregation_layer <- df %>%  group_by(aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
View(df_aggregation_layer)
# By context and source
df_context <- df %>%  group_by(context) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_aggregation_layer)
xtable(df_context)
View(df_context)
# By tokenization
df_context <- df %>%  group_by(tokenization) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
# By tokenization
df_tokenization <- df %>%  group_by(tokenization) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_tokenization)
View(df_tokenization)
preprocess <- function(x) {
return(x)
}
preprocess("a")
preprocess <- function(df) {
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
preprocess(df)
############################General results##################################
# Pre-processing
df <- read.csv2("results/discourse_connective_results.csv")
preprocess(df)
############################General results##################################
# Pre-processing
df <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df2 <- preprocess(read.csv2("results/frazer_results.csv"))
############################General results##################################
# Pre-processing
df <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df2 <- preprocess(read.csv2("results/frazer_results.csv"))
preprocess <- function(df) {
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
############################General results##################################
# Pre-processing
df <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df2 <- preprocess(read.csv2("results/frazer_results.csv"))
View(df)
View(df2)
############################General results##################################
# Pre-processing
df_dc <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df_fr <- preprocess(read.csv2("results/frazer_results.csv"))
df_total <- rbind(df_dc, df_fr)
############################General results##################################
# Pre-processing
preprocess <- function(df) {
df$accuracy <- as.numeric(df$accuracy)
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
df_dc <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df_fr <- preprocess(read.csv2("results/frazer_results.csv"))
df_total <- rbind(df_dc, df_fr)
# By aggregation and layers
df_aggregation_layer <- df %>%  group_by(aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_aggregation_layer)
# By aggregation and layers
df_aggregation_layer <- df_total %>%  group_by(aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_aggregation_layer)
# By context
df_context <- df_total %>%  group_by(context) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_context)
# By tokenization
df_tokenization <- df_total %>%  group_by(tokenization) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
xtable(df_tokenization)
############################General results##################################
# Pre-processing
preprocess <- function(df) {
df$accuracy <- as.numeric(df$accuracy)
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
df_dc <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df_fr <- preprocess(read.csv2("results/frazer_results.csv"))
df_total <- rbind(df_dc, df_fr)
# By aggregation and layers
df_aggregation_layer <- df_total %>%  group_by(aggregation, layer) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
# By context
df_context <- df_total %>%  group_by(context) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
# By tokenization
df_tokenization <- df_total %>%  group_by(tokenization) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
# By tokenization
df_dc %>% arrange(accuracy)
# By tokenization
df_dc %>% arrange(-accuracy)
# By tokenization
head(df_dc) %>% arrange(-accuracy)
head(df_fr) %>% arrange(-accuracy)
View(df_dc)
# By tokenization
df_dc %>% arrange(-accuracy)
head(df_fr) %>% arrange(-accuracy) %>% head()
head(df_fr) %>% arrange(-accuracy)
# By tokenization
df_dc %>% arrange(-accuracy) %>% head()
df_fr %>% arrange(-accuracy) %>% head()
df_dc %>%  group_by(accuracy) %>% arrange(-accuracy) %>% head()
df_dc %>%  group_by(total_predictions) %>% arrange(-accuracy) %>% head()
df_dc %>%  group_by(total_predictions) %>% arrange(-accuracy)
df_dc %>%  group_by(total_predictions) %>% arrange(-accuracy)
df_dc %>% group_by(total_predictions) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_fr %>% group_by(total_predictions) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_fr %>% group_by(accuracy) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
total_predictions
df_fr %>% group_by(source) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_dc %>% group_by(source) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE)) %>% arrange(-mean_accuracy)
df_dc %>% group_by(source) %>%  summarize(mean_accuracy_t1 = mean(accuracy, na.rm = FALSE))
df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE))
df_tcomparison <- df_dc %>% group_by(source) %>%  summarize(mean_accuracy_t1 = mean(accuracy, na.rm = FALSE))
df_tcomparison <- rbind(df_tcomparison,df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE)))
df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE))
df_tcomparison2 <- df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE))
df_tcomparison <- rbind(df_tcomparison, df_tcomparison2)
df_tcomparison
df_tcomparison2
df_tcomparison <- merge(df_tcomparison, df_tcomparison2)
df_tcomparison
df_fr %>% arrange(-accuracy) %>% head()
# By task
df_dc %>% arrange(-accuracy) %>% head()
# By task
df_dc %>% arrange(-accuracy) %>% head()
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
View(df)
df %>% select(-Before)
df %>% select(-Before, PM, After)
df %>% select(-Before, After)
df %>% select(-Before, After, PM, Category)
df %>% select(-c(Before, After, PM, Category))
test <- df %>% select(-c(Before, After, PM, Category))
unlist(test)
# Initialize a vector to store counts
counts <- integer(length(unlist(test)))
# Count occurrences of each word in the Before sentences
for (i in seq_along(words_to_count)) {
counts[i] <- sum(str_count(df$Before, fixed(words_to_count[i], ignore_case = TRUE)))
}
# Select the columns of interest (excluding 'Before', 'After', 'PM', 'Category')
words_to_count_df <- df %>% select(-c(Before, After, PM, Category))
# Flatten the data frame to get a vector of words to count
words_to_count <- unlist(words_to_count_df)
# Initialize a vector to store counts
counts <- integer(length(words_to_count))
# Count occurrences of each word in the Before sentences
for (i in seq_along(words_to_count)) {
counts[i] <- sum(str_count(df$Before, fixed(words_to_count[i], ignore_case = TRUE)))
}
# Combine the results into a data frame
results_df <- data.frame(
Word = words_to_count,
Count = counts
)
# Display the result
print(results_df)
# Select the columns of interest (excluding 'Before', 'After', 'PM', 'Category')
words_to_count_df <- df %>% select(-c(Before, After, PM, Category))
View(words_to_count_df)
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
words_to_count_df <- df %>% select(-c(Before, After, PM, Category))
unique_words <- unique(df$PM)
for (word in unique_words) {
words_to_count_df[[word]] <- NA  # Add empty column with NA values
}
View(words_to_count_df)
ncol(words_to_count_df)
ncol(words_to_count_df)-unique_words
ncol(words_to_count_df)-length(unique_words)
words_to_count_df[1, 74]
words_to_count_df[1, 75]
words_to_count_df[0, 74]
words_to_count_df[1, 74]
words_to_count_df[-1, 74]
words_to_count_df[1, 74]
for (j in 1:ncol(words_to_count_df)-length(unique_words)) {
# Get the current word from the AOC columns
current_word <- words_to_count_df[i, j]
}
print(current_word)
for (j in 1:ncol(words_to_count_df)-length(unique_words)) {
# Get the current word from the AOC columns
current_word <- words_to_count_df[i, j]
print(current_word)
}
for (j in 1:ncol(words_to_count_df)-length(unique_words)) {
# Get the current word from the AOC columns
current_word <- words_to_count_df[1, j]
print(current_word)
}
for (j in 1:ncol(words_to_count_df)-length(unique_words)) {
# Get the current word from the AOC columns
print(words_to_count_df[1, j])
}
for (i in 1:nrow(df)) {
for (j in 1:ncol(words_to_count_df)-length(unique_words)) {
# Get the current word from the AOC columns
print(words_to_count_df[i, j])
}
}
df %>% na_if("None")
df %>% na_if("NA")
df %>% rowwise()
df %>% rowwise() %>%
df %>% rowwise() %>%
mutate(count = sum(!is.na(c_across(color_1:color_4))
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
words_to_count_df <- df %>% select(-c(Before, After, PM, Category))
words_to_count_df %>%
pivot_longer(cols = everything(), names_to = NULL, values_to = 'var') %>%
count(var, name = "count")
words_to_count_df <- df %>% select(-c(Before, After, PM))
words_to_count_df %>%
pivot_longer(cols = everything(), names_to = NULL, values_to = 'var') %>%
count(var, name = "count")
words_to_count_df %>% group_by(Category) %>%
pivot_longer(cols = everything(), names_to = NULL, values_to = 'var') %>%
count(var, name = "count")
words_to_count_df %>% group_by(Category)
words_to_count_df %>% group_by(Category) %>%
pivot_longer(cols = everything(), names_to = NULL, values_to = 'var') %>%
count(var, name = "count")
words_to_count_df %>%
pivot_longer(cols = -Category, names_to = NULL, values_to = "word") %>%  # Pivot longer, excluding Category
filter(!is.na(word)) %>%  # Remove NA values, if any
count(Category, word, name = "count")
word_counts <- words_to_count_df %>%
pivot_longer(cols = -Category, names_to = NULL, values_to = "word") %>%  # Pivot longer, excluding Category
filter(!is.na(word)) %>%  # Remove NA values, if any
count(Category, word, name = "count")
View(word_counts)
words_to_count_df <- df %>% select(-c(Before, After))
predictions_df <- df %>% select(-c(Before, After))
View(predictions_df)
predictions_df %>%
mutate(correct = rowSums(.[, -1] == PM),
incorrect = rowSums(.[, -1] != PM))
predictions_df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category, PM) %>%                       # Group by Category and PM
summarise(total_correct = sum(correct),          # Total correct predictions
total_incorrect = sum(incorrect),      # Total incorrect predictions
.groups = 'drop')
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category, PM) %>%                       # Group by Category and PM
summarise(total_correct = sum(correct),          # Total correct predictions
total_incorrect = sum(incorrect),      # Total incorrect predictions
.groups = 'drop')
View(predictions_df)
predictions_df %>% group_by(Category)
predictions_df %>% group_by(Category) %>% count()
predictions_df %>% group_by(Category) %>% mean()
predictions_df %>% group_by(Category) %>% summ()
predictions_df %>% group_by(Category) %>% sum()
predictions_df %>% group_by(Category) %>% sum()
predictions_df %>% group_by(Category, total_correct, total_incorrect) %>% sum()
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category, PM) %>%                       # Group by Category and PM
summarise(total_correct = sum(correct),          # Total correct predictions
total_incorrect = sum(incorrect),      # Total incorrect predictions
.groups = 'drop')
summary_df <- predictions_df %>%
group_by(Category) %>%                        # Group by Category
summarise(
total_correct = sum(total_correct, na.rm = TRUE),  # Sum total_correct
total_incorrect = sum(total_incorrect, na.rm = TRUE),  # Sum total_incorrect
.groups = 'drop'                           # Drop grouping for final output
)
View(summary_df)
predictions_df %>%
group_by(Category) %>%                        # Group by Category
summarise(
total_correct = sum(total_correct, na.rm = TRUE),  # Sum total_correct
total_incorrect = sum(total_incorrect, na.rm = TRUE),  # Sum total_incorrect
percentage = total_correct/(total_correct+total_incorrect)
.groups = 'drop'                           # Drop grouping for final output
predictions_df %>%
group_by(Category) %>%                        # Group by Category
summarise(
total_correct = sum(total_correct, na.rm = TRUE),  # Sum total_correct
total_incorrect = sum(total_incorrect, na.rm = TRUE),  # Sum total_incorrect
percentage = total_correct/(total_correct+total_incorrect),
.groups = 'drop'                           # Drop grouping for final output
)
predictions_df %>%
group_by(Category) %>%                        # Group by Category
summarise(
total_correct = sum(total_correct, na.rm = TRUE),  # Sum total_correct
total_incorrect = sum(total_incorrect, na.rm = TRUE),  # Sum total_incorrect
percentage = (total_correct/(total_correct+total_incorrect))*100,
.groups = 'drop'                           # Drop grouping for final output
)
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category, PM) %>%                       # Group by Category and PM
summarise(total_correct = sum(correct),          # Total correct predictions
total_incorrect = sum(incorrect),      # Total incorrect predictions
.groups = 'drop')
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category) %>%                       # Group by Category and PM
summarise(
total_correct = sum(total_correct, na.rm = TRUE),  # Sum total_correct
total_incorrect = sum(total_incorrect, na.rm = TRUE),  # Sum total_incorrect
percentage = (total_correct/(total_correct+total_incorrect))*100,
.groups = 'drop'                           # Drop grouping for final output
)
df %>%
mutate(correct = rowSums(.[, -1] == PM),       # Count correct predictions
incorrect = rowSums(.[, -1] != PM)) %>%  # Count incorrect predictions
select(Category, PM, correct, incorrect) %>%    # Select relevant columns for the final output
group_by(Category) %>%                       # Group by Category and PM
summarise(total_correct = sum(correct),          # Total correct predictions
total_incorrect = sum(incorrect),
percentage = (total_correct/(total_correct+total_incorrect))*100,
.groups = 'drop')
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
View(df)
View(predictions_df)
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM),
incorrect = rowSums(.[, -1] != PM)) %>%
select(Category, PM, correct, incorrect) %>%
group_by(Category) %>%
summarise(total_correct = sum(correct),
total_incorrect = sum(incorrect),
percentage = (total_correct/(total_correct+total_incorrect))*100,
.groups = 'drop')
