)
summary(t_df_config)
t_df_config$experiment = rownames(t_df_config)
summary(t_df_config)
View(t_df_config)
t_df_config[1:ncol(t_df_config)]
View(t_df_config)
rownames(t_df_config) <- NULL
View(t_df_config)
preprocess(t_df_config)
preprocess2 <- function(df) {
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
preprocess2(t_df_config)
View(t_df_config)
t_df_config %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col)
t_df_config %>%
mutate(split_col = str_split(experiment, "/"))
t_df_config %>%
mutate(split_col = str_split(experiment, "."))
t_df_config %>%
mutate(split_col = str_split(experiment, ".")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
)
t_df_config %>%
mutate(split_col = str_split(experiment, "\\.")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
)
preprocess2 <- function(df) {
df <-  df %>%
mutate(split_col = str_split(experiment, "\\.")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col)
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
preprocess2(t_df_config)
df_config <- preprocess2(t_df_config)
View(df_config)
View(df_config)
df_config %>% group_by(source, basic_percentage)
df_config %>% group_by(source, basic_percentage) %>% summarize(mean_accuracy = mean(accuracy, na.rm = FALSE))
df_config %>% group_by(source, basic_percentage) %>% summarize(mean_accuracy = mean(basic_percentage, na.rm = FALSE))
df_config %>% group_by(source) %>% summarize(mean_accuracy = mean(basic_percentage, na.rm = FALSE))
df_config %>% group_by(source) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = FALSE),
commentary_accuracy = mean(commentary_percentage, na.rm = FALSE),)
df_config %>% group_by(source) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),)
df_config %>% group_by(source) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
df_config %>% group_by(source, encoder) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
df_config %>% group_by(source, encoder) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
df_config %>% group_by(source, context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By source
df_config_source <- df_config %>% group_by(source) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By context
df_config_context <- df_config %>% group_by(context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_context)
View(df_config_source)
# By tokenization
df_config_context <- df_config %>% group_by(context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By tokenization
df_config_tokenization <- df_config %>% group_by(context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_tokenization)
# By tokenization
df_config_tokenization <- df_config %>% group_by(tokenization) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config)
# By tokenization
df_config_tokenization <- df_config %>% group_by(aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By tokenization
df_config_ggregation <- df_config %>% group_by(aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_ggregation)
View(df_config_context)
View(df_config_tokenization)
View(df_config_ggregation)
# By source,
df_config_source_context <- df_config %>% group_by(source, context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_source_context)
# By tokenization
df_config_context_tokenization <- df_config %>% group_by(context, tokenization) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_context_tokenization)
# By context and tokenization
df_config_context_tokenization <- df_config %>% group_by(context, tokenization) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By source and context
df_config_source_context <- df_config %>% group_by(source, context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config)
df_config %>% group_by(source, aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
df_config %>% group_by(aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
df_config %>% group_by(context, aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
# By source and context
df_config_context_aggregation <- df_config %>% group_by(context, aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
View(df_config_context_aggregation)
xtable(predictions_df)
xtable(df_config_context_aggregation)
library(dplyr)
library(stringr)
library(tidyverse)
library(xtable)
library(data.table)
library(dplyr)
library(stringr)
library(tidyverse)
library(xtable)
library(data.table)
############################General results##################################
# Pre-processing
preprocess <- function(df) {
df$accuracy <- as.numeric(df$accuracy)
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
df_dc <- preprocess(read.csv2("results/discourse_connective_results.csv"))
df_fr <- preprocess(read.csv2("results/frazer_results.csv"))
df_total <- rbind(df_dc, df_fr)
# By aggregation
df_aggregation <- df_total %>%  group_by(source, aggregation) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(source, -mean_accuracy)
xtable(df_aggregation)
xtable(df_aggregation, , include.rownames=FALSE)
xtable(df_aggregation, include.rownames=FALSE)
xtable(df_aggregation, include.rownames=FALSE)
xtable(df_aggregation, include.rownames=TRUE)
xtable(df_aggregation, include.rownames=FALSE)
print(xtable(df_aggregation), include.rownames=FALSE)
############################Randomized baseline#################################
# Discourse connective
df <- read.csv2("data/discourse_connective/probing_data.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_distribution <- df %>% group_by(PM) %>% count()
random_baseline_accuracy <- 1 / n_markers
1 / n_markers
cat("Randomized Baseline Accuracy:", random_baseline_accuracy, "\n")
n_markers
samples
length(unique(df$PM))
# Discourse connective
df <- read.csv2("data/frazer_categorization/probing_data_2.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_markers
samples
total_randomized_baseline <- (1 / 14) * 500 + (1/25) * 226
total_randomized_baseline
total_samples <- 500 + 226
total_randomized_baseline <- ((1 / 14) * 500 + (1 / 25) * 226) / total_samples
total_randomized_baseline
((1 / 14) * 500 + (1 / 25) * 226) / (500 + 226)
total_randomized_baseline <- (((1 / 14) * 500 + (1 / 25) * 226) / (500 + 226))*100
# By aggregation and layers
df_aggregation_layer <- df_total %>% group_by(source, aggregation, layer) %>%
summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(source, desc(mean_accuracy)) %>%
slice_max(mean_accuracy, n = 3, with_ties = FALSE) %>% ungroup()
print(xtable(df_aggregation_layer), include.rownames=FALSE)
# By context
df_context <- df_total %>%  group_by(source, context) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(source, -mean_accuracy)
print(xtable(df_context), include.rownames=FALSE)
# By tokenization
df_tokenization <- df_total %>%  group_by(source, tokenization) %>%  summarize(mean_accuracy = mean(accuracy, na.rm = FALSE)) %>% arrange(source, -mean_accuracy)
print(xtable(df_tokenization), include.rownames=FALSE)
# By task
df_tcomparison <- df_dc %>% group_by(source) %>%  summarize(mean_accuracy_t1 = mean(accuracy, na.rm = FALSE))
df_tcomparison2 <- df_fr %>% group_by(source) %>%  summarize(mean_accuracy_t2 = mean(accuracy, na.rm = FALSE))
df_tcomparison <- merge(df_tcomparison, df_tcomparison2)
xtable(df_tcomparison)
print(xtable(df_tcomparison), include.rownames=FALSE)
df <- read.csv2("data/discourse_connective/probing_data.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_distribution <- df %>% group_by(PM) %>% count()
random_baseline_accuracy <- 1 / n_markers
expected_correct_predictions <- random_baseline_accuracy * samples
cat("Randomized Baseline Accuracy:", random_baseline_accuracy, "\n")
cat("Expected Number of Correct Predictions (Random Baseline):", expected_correct_predictions, "\n")
cat("Total Number of Samples:", samples, "\n")
cat("Number of Unique Markers:", n_markers, "\n")
df <- read.csv2("data/frazer_categorization/probing_data_2.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_distribution <- df %>% group_by(PM) %>% count()
random_baseline_accuracy <- 1 / n_markers
expected_correct_predictions <- random_baseline_accuracy * samples
cat("Randomized Baseline Accuracy:", random_baseline_accuracy, "\n")
cat("Expected Number of Correct Predictions (Random Baseline):", expected_correct_predictions, "\n")
cat("Total Number of Samples:", samples, "\n")
cat("Number of Unique Markers:", n_markers, "\n")
df <- read.csv2("data/discourse_connective/probing_data.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_distribution <- df %>% group_by(PM) %>% count()
random_baseline_accuracy <- 1 / n_markers
expected_correct_predictions <- random_baseline_accuracy * samples
cat("Randomized Baseline Accuracy:", random_baseline_accuracy, "\n")
cat("Expected Number of Correct Predictions (Random Baseline):", expected_correct_predictions, "\n")
cat("Total Number of Samples:", samples, "\n")
cat("Number of Unique Markers:", n_markers, "\n")
df <- read.csv2("data/frazer_categorization/probing_data_2.csv")
samples <- length(df$Before)
n_markers <- length(unique(df$PM))
n_distribution <- df %>% group_by(PM) %>% count()
random_baseline_accuracy <- 1 / n_markers
expected_correct_predictions <- random_baseline_accuracy * samples
cat("Randomized Baseline Accuracy:", random_baseline_accuracy, "\n")
cat("Expected Number of Correct Predictions (Random Baseline):", expected_correct_predictions, "\n")
cat("Total Number of Samples:", samples, "\n")
cat("Number of Unique Markers:", n_markers, "\n")
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
# In general
predictions_df <- df %>%
mutate(correct = rowSums(.[, -1] == PM, na.rm = TRUE),
incorrect = rowSums(.[, -1] != PM,na.rm = TRUE)) %>%
select(Category, PM, correct, incorrect) %>%
group_by(Category) %>%
summarise(total_correct = sum(correct),
total_incorrect = sum(incorrect),
percentage = (total_correct/(total_correct+total_incorrect))*100,
.groups = 'drop')
print(xtable(predictions_df), include.rownames=FALSE)
# By configuration
df_config <- df[4:length(colnames(df))]
df_config$PM <- df$PM
df_config <- df_config %>%
mutate(across(2:(ncol(df_config)-1), ~ if_else(. == PM, 1, 0)))
df_config <- df_config[1:(length(df_config)-1)]
unique_sum <- df_config %>% group_by(Category) %>%
summarize(total = n())
df_config <- df_config %>% group_by(Category) %>% summarise_all(sum)
t_df_config <- data.frame(t(df_config[-1]))
colnames(t_df_config) <- df_config$Category
t_df_config <- t_df_config %>%
mutate(
basic_total = unique_sum$total[unique_sum$Category == "basic"],
commentary_total = unique_sum$total[unique_sum$Category == "commentary"],
discourse_total = unique_sum$total[unique_sum$Category == "discourse"],
parallel_total = unique_sum$total[unique_sum$Category == "parallel"]
) %>%
# Calculate the percentage of correct predictions
mutate(
basic_percentage = (basic / basic_total) * 100,
commentary_percentage = (commentary / commentary_total) * 100,
discourse_percentage = (discourse / discourse_total) * 100,
parallel_percentage = (parallel / parallel_total) * 100
)
summary(t_df_config)
t_df_config$experiment = rownames(t_df_config)
rownames(t_df_config) <- NULL
preprocess2 <- function(df) {
df <-  df %>%
mutate(split_col = str_split(experiment, "\\.")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col)
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
df_config <- preprocess2(t_df_config)
# By context and tokenization
df_config_context_tokenization <- df_config %>% group_by(context, tokenization) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
print(xtable(df_config_context_tokenization), include.rownames=FALSE)
View(df_config_context_tokenization)
unique_sum <- df_config %>% group_by(Category) %>%
summarize(total = n())
View(unique_sum)
sum(unique_sum)
sum(unique_sum[2])
72/226
df_fr
View(df_fr)
############################Fraser Task##################################
df <- read.csv2("results/frazer_predictions.csv")
View(df)
# By source and context
df_config_source_context <- df_config %>% group_by(source, context) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
print(xtable(df_config_source_context), include.rownames=FALSE)
df_config_context_aggregation <- df_config %>% group_by(context, aggregation) %>% summarize(
basic_accuracy = mean(basic_percentage, na.rm = TRUE),
commentary_accuracy = mean(commentary_percentage, na.rm = TRUE),
parallel_accuracy = mean(parallel_percentage, na.rm = TRUE),
discourse_accuracy = mean(discourse_percentage, na.rm = TRUE))
print(xtable(df_config_context_aggregation), include.rownames=FALSE)
############################General results##################################
# Pre-processing
preprocess <- function(df) {
df$accuracy <- as.numeric(df$accuracy)
df <- df %>%
mutate(split_col = str_split(experiment, "/")) %>%
mutate(
context = map_chr(split_col, 1),
language = map_chr(split_col, 2),
model = map_chr(split_col, 3),
tokenization = map_chr(split_col, 4),
layer = map_chr(split_col, 5),
aggregation = map_chr(split_col, 6)
) %>%
select(-split_col) # remove temporary split column
df <- df %>%
mutate(
source = case_when(
language == "en" & model == "multi" ~ "mBert_base",
language == "en" & model == "mono" ~ "Bert_base",
language == "en2" & model == "mono" ~ "Bert_large",
TRUE ~ NA_character_  # Or any default value if none of the conditions match
)
)
return(df)
}
df_dc <- preprocess(read.csv2("results/discourse_connective_results.csv"))
print(xtable(df_dc), include.rownames=FALSE)
df_dc
View(df_dc)
df_dc %>% select(-c(experiment, total_predictions))
df_dc %>% select(-c(experiment, total_predictions, correct_predictions))
df_dc %>% select(-c(experiment, total_predictions, correct_predictions, language, model))
df_dc[,c(1,3,2,4)]
colnames(df_dc)
df_dc[,c(12,6,9,11,10)]
colnames(df_dc[,c(12,6,9,11,10)])
colnames(df_dc)
colnames(df_dc[,c(12,6,9,11,10,5,4)])
df_dc <- df_dc[,c(12,6,9,11,10,5,4)])
View(df_dc)
df_dc <- df_dc[,c(12,6,9,11,10,5,4)]
View(df_dc)
df_dc %>% arrange(source, context, tokenization, aggregation, layer)
df_dc <- df_dc %>% arrange(source, context, tokenization, aggregation, layer)
df_dc
print(xtable(df_dc), include.rownames=FALSE)
df$layer <- as.numeric(df$layer)
df_dc$layer <- as.numeric(df_dc$layer)
df_dc <- df_dc %>% arrange(source, context, tokenization, aggregation, layer)
print(xtable(df_dc), include.rownames=FALSE)
df_fr <- preprocess(read.csv2("results/frazer_results.csv"))
View(df_dc)
df_fr <- df_fr[,c(12,6,9,11,10,5,4)]
df_fr$layer <- as.numeric(df_fr$layer)
df_fr <- df_fr %>% arrange(source, context, tokenization, aggregation, layer)
print(xtable(df_fr), include.rownames=FALSE)
